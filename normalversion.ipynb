{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellId":"g4treu8xd597cku3k847j","trusted":true},"outputs":[],"source":["#!g1.1\n","import torch\n","from torch import nn\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from tqdm.notebook import tqdm\n","import os\n","import pandas as pd\n","import numpy as np\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","class CustomImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, indices=None):\n","        self.img_labels = pd.read_csv(annotations_file)\n","        if indices is not None:\n","            self.img_labels = self.img_labels.loc[indices,:]\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path).type(torch.FloatTensor).to(device)\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"ibvogrnn8qrhfs5xuz8acj","trusted":true},"outputs":[],"source":["#!g1.1\n","split_df = pd.read_csv(\"/kaggle/input/bhw-1-deep-learning/bhw1-dataset/labels.csv\")\n","train_idx = np.array([])\n","test_idx = np.array([])\n","for i in range(200):\n","    tmp = np.random.permutation(np.array(split_df[split_df[\"Label\"] == i].index.tolist()))\n","    train_idx = np.append(train_idx, tmp[:490])\n","    test_idx = np.append(test_idx, tmp[490:500])"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"yzybp9vtkmv421j6nt6be","trusted":true},"outputs":[],"source":["#!g1.1\n","from torch.utils.data import DataLoader, random_split\n","import torchvision.transforms as T\n","normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","train_transform = T.Compose([\n","    T.RandomResizedCrop(224, scale=(0.5, 1.0)),\n","    T.RandomHorizontalFlip(p=0.5),\n","    T.GaussianBlur(3, (0.1, 4)),\n","    T.RandomInvert(p=0.05),\n","    T.RandomGrayscale(p=0.1),\n","    normalize,\n","])\n","test_transform = T.Compose([\n","    T.Resize(256),\n","    T.CenterCrop(224),\n","    normalize,\n","])\n","train_dataset = CustomImageDataset(\"/kaggle/input/bhw-1-deep-learning/bhw1-dataset/labels.csv\", \n","                                   \"/kaggle/input/bhw-1-deep-learning/bhw1-dataset/trainval\", \n","                                   transform=train_transform, \n","                                   indices=train_idx)\n","\n","val_dataset = CustomImageDataset(\"/kaggle/input/bhw-1-deep-learning/bhw1-dataset/labels.csv\", \n","                                   \"/kaggle/input/bhw-1-deep-learning/bhw1-dataset/trainval\", \n","                                   transform=test_transform, \n","                                   indices=test_idx)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=False)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"u8vm7cr4zw3t7hw58r40p","trusted":true},"outputs":[],"source":["#!g1.1\n","sns.set_style('whitegrid')\n","plt.rcParams.update({'font.size': 15})\n","\n","\n","def plot_losses(train_losses, test_losses, train_accuracies, test_accuracies):\n","    clear_output()\n","    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n","    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label='train')\n","    axs[0].plot(range(1, len(test_losses) + 1), test_losses, label='test')\n","    axs[0].set_ylabel('loss')\n","\n","    axs[1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label='train')\n","    axs[1].plot(range(1, len(test_accuracies) + 1), test_accuracies, label='test')\n","    axs[1].set_ylabel('accuracy')\n","\n","    for ax in axs:\n","        ax.set_xlabel('epoch')\n","        ax.legend()\n","\n","    plt.show()\n","    \n","def training_epoch(model, optimizer, criterion, train_loader, tqdm_desc):\n","    train_loss, train_accuracy = 0.0, 0.0\n","    model.train()\n","    for images, labels in tqdm(train_loader, desc=tqdm_desc):\n","        images = images.to(device)  # images: batch_size x num_channels x height x width\n","        labels = labels.to(device)  # labels: batch_size\n","\n","        optimizer.zero_grad()\n","        logits = model(images)  # logits: batch_size x num_classes\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * images.shape[0]\n","        train_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n","    \n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy /= len(train_loader.dataset)\n","    return train_loss, train_accuracy\n","\n","\n","@torch.no_grad()\n","def validation_epoch(model, criterion, test_loader, tqdm_desc):\n","    test_loss, test_accuracy = 0.0, 0.0\n","    model.eval()\n","    for images, labels in tqdm(test_loader, desc=tqdm_desc):\n","        images = images.to(device)  # images: batch_size x num_channels x height x width\n","        labels = labels.to(device)  # labels: batch_size\n","        logits = model(images)  # logits: batch_size x num_classes\n","        loss = criterion(logits, labels)\n","\n","        test_loss += loss.item() * images.shape[0]\n","        test_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy /= len(test_loader.dataset)\n","    return test_loss, test_accuracy\n","\n","    \n","def train(model, optimizer, scheduler, criterion, train_loader, test_loader, num_epochs):\n","    train_losses, train_accuracies = [], []\n","    test_losses, test_accuracies = [], []\n","\n","    for epoch in range(1, num_epochs + 1):\n","        train_loss, train_accuracy = training_epoch(\n","            model, optimizer, criterion, train_loader,\n","            tqdm_desc=f'Training {epoch}/{num_epochs}'\n","        )\n","        test_loss, test_accuracy = validation_epoch(\n","            model, criterion, test_loader,\n","            tqdm_desc=f'Validating {epoch}/{num_epochs}'\n","        )\n","\n","        if scheduler is not None:\n","            scheduler.step(test_loss)\n","\n","        train_losses += [train_loss]\n","        train_accuracies += [train_accuracy]\n","        test_losses += [test_loss]\n","        test_accuracies += [test_accuracy]\n","        plot_losses(train_losses, test_losses, train_accuracies, test_accuracies)\n","\n","    return train_losses, test_losses, train_accuracies, test_accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"wyiq3v0zekez9eabr84ce","trusted":true},"outputs":[],"source":["#!g1.1\n","class TestDataset(Dataset):\n","    def __init__(self, transform=None):\n","        self.img_dir = \"/kaggle/input/bhw-1-deep-learning/bhw1-dataset/test\"\n","        self.transform = transform\n","        self.img_labels = sorted(os.listdir(\"/kaggle/input/bhw-1-deep-learning/bhw1-dataset/test\"))\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        \n","        img_path = os.path.join(self.img_dir, self.img_labels[idx])\n","        image = read_image(img_path).type(torch.FloatTensor)\n","        label = self.img_labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"t3cnm9tbepgdphat7dqc7j","trusted":true},"outputs":[],"source":["#!g1.1\n","from torchvision.models import mobilenet_v2\n","\n","model = mobilenet_v2(num_classes=200).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"pceh712n64axxbj2omtwa","execution_id":"51ca0c3e-de65-4c01-a184-2a0ff73ae44f","trusted":true},"outputs":[],"source":["#!g1.1\n","num_epochs = 50\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.045, momentum=0.9, weight_decay=0.00004, nesterov=True)\n","criterion = torch.nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n","train_losses, test_losses, train_accuracies, test_accuracies = train(\n","    model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_epoch = 5\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.004, momentum=0.9, weight_decay=0.00004, nesterov=True)\n","criterion = torch.nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","train_losses, test_losses, train_accuracies, test_accuracies = train(\n","    model, optimizer, scheduler, criterion, train_loader, val_loader, num_epoch\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_epoch = 5\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.00004, nesterov=True)\n","train_losses, test_losses, train_accuracies, test_accuracies = train(\n","    model, optimizer, scheduler, criterion, train_loader, val_loader, num_epoch\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, pin_memory=True)\n","num_epoch = 12\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.00004, nesterov=True)\n","train_losses, test_losses, train_accuracies, test_accuracies = train(\n","    model, optimizer, scheduler, criterion, train_loader, val_loader, num_epoch\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epoch = 16\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.9, weight_decay=0, nesterov=True)\n","train_losses, test_losses, train_accuracies, test_accuracies = train(\n","    model, optimizer, scheduler, criterion, train_loader, val_loader, num_epoch\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"29p6gwzv7zwj3jobt0jcbl","execution_id":"5025142b-0aa5-45f8-9e7f-87c5a603ebb9","trusted":true},"outputs":[],"source":["#!g1.1\n","test_dataset = TestDataset(transform=test_transform)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=False)\n","df = pd.DataFrame(columns=[\"Id\", \"Label\"])\n","# model.to(\"cpu\")\n","model.eval()\n","for images, labels in tqdm(test_loader):\n","    images = images.to(device)  # images: batch_size x num_channels x height x width\n","    labels = labels  # labels: batch_size\n","    logits = model(images)\n","    preds = logits.argmax(dim=1)\n","    # print(labels, preds)\n","    tmp = pd.DataFrame(data={\"Id\": labels, \"Label\": preds.detach().cpu().numpy()})\n","    df = pd.concat([df, tmp], ignore_index=True)\n","\n","df.to_csv(\"MobileNet_77epoch.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"notebookId":"0296a016-7cbc-4c08-9f5c-287ca905ceab","notebookPath":"Untitled1.ipynb"},"nbformat":4,"nbformat_minor":5}
